{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs4jFRGTKxAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de2b642c-d470-433c-9855-a5a7e6e78aaa"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "#header column added to data\n",
        "wdbc = pd.read_csv('wdbc.data')\n",
        "\n",
        "X = wdbc.drop(['ID','diagnosis'], axis=1)\n",
        "y = wdbc['diagnosis']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "predictions = mlp.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[84  3]\n",
            " [ 3 53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REKj5Evu9bFn"
      },
      "source": [
        "With the first classifier, we set it up with three hidden layers that are as large as the amount of inputs. With the default iterations of 200, it does not converge, so we increase it to 500 below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH3yXhPH-duO",
        "outputId": "f1d50150-f1ac-40be-b1d5-1809df9a7afc"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "#header column added to data\n",
        "wdbc = pd.read_csv('wdbc.data')\n",
        "\n",
        "X = wdbc.drop(['ID','diagnosis'], axis=1)\n",
        "y = wdbc['diagnosis']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30),max_iter=500)\n",
        "mlp.fit(X_train,y_train)\n",
        "\n",
        "predictions = mlp.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "print(classification_report(y_test,predictions))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[87  1]\n",
            " [ 2 53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.98      0.99      0.98        88\n",
            "           M       0.98      0.96      0.97        55\n",
            "\n",
            "    accuracy                           0.98       143\n",
            "   macro avg       0.98      0.98      0.98       143\n",
            "weighted avg       0.98      0.98      0.98       143\n",
            "\n"
          ]
        }
      ]
    }
  ]
}